{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cedric/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataloader import GraphTextDataset, GraphDataset, TextDataset, AddRWStructEncoding\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from Model import Model\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import get_scheduler\n",
    "import gensim\n",
    "from nltk import word_tokenize\n",
    "import torch\n",
    "from torch import optim\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "with open('graph_config.json') as f:\n",
    "    graph_config = json.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = config['model_name']\n",
    "model_type = config['model_type']\n",
    "nout = config['nout']\n",
    "nhid = config['nhid']\n",
    "nb_epochs = config['nb_epochs']\n",
    "batch_size_train = config['batch_size_train']\n",
    "batch_size_test = config['batch_size_test']\n",
    "learning_rate = config['learning_rate']\n",
    "load_graph_pretrained = config['load_graph_pretrained']\n",
    "\n",
    "walk_length = graph_config['walk_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type=='text':\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "else:\n",
    "    tokenizer = None\n",
    "if model_type=='w2v':\n",
    "    model_w2v = gensim.models.KeyedVectors.load_word2vec_format(model_name + '.txt')\n",
    "    w2v_embeddings = np.zeros((len(model_w2v.vectors)+1, model_w2v.vectors.shape[1]), dtype=np.float32)\n",
    "    w2v_embeddings[1:] = model_w2v.vectors\n",
    "    nltk_tokenizer = word_tokenize\n",
    "    word2idx = model_w2v.key_to_index\n",
    "else:\n",
    "    nltk_tokenizer = None\n",
    "    word2idx = None\n",
    "    w2v_embeddings = None\n",
    "gt = np.load(\"./data/token_embedding_dict.npy\", allow_pickle=True)[()]\n",
    "\n",
    "val_dataset = GraphTextDataset(root='./data/', gt=gt, split='val', tokenizer=tokenizer, \n",
    "                               nltk_tokenizer=nltk_tokenizer, word2idx=word2idx, \n",
    "                               graph_transform=AddRWStructEncoding(walk_length))\n",
    "train_dataset = GraphTextDataset(root='./data/', gt=gt, split='train', tokenizer=tokenizer, \n",
    "                                 nltk_tokenizer=nltk_tokenizer, word2idx=word2idx, \n",
    "                                 graph_transform=AddRWStructEncoding(walk_length))\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE = torch.nn.CrossEntropyLoss()\n",
    "def contrastive_loss(v1, v2):\n",
    "  batch_size = v1.shape[0]\n",
    "  logits = torch.matmul(v1,torch.transpose(v2, 0, 1))\n",
    "  labels = torch.arange(logits.shape[0], device=v1.device)\n",
    "  return ((CE(logits, labels) + CE(torch.transpose(logits, 0, 1), labels))/2)*(16/batch_size)\n",
    "\n",
    "model = Model(model_name, nout, nhid, graph_config, load_graph_pretrained=load_graph_pretrained, \n",
    "              model_type=model_type, w2v_embeddings=w2v_embeddings)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "                                betas=(0.9, 0.999),\n",
    "                                weight_decay=config['weight_decay'], \n",
    "                                eps=1e-08)\n",
    "\n",
    "lr_scheduler = get_scheduler('cosine', optimizer=optimizer, num_warmup_steps=config['num_warmup_steps'], \n",
    "                             num_training_steps=len(train_loader)*nb_epochs*config['scheduler_steps_factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 16,789,200\n",
      "    Graph encoder: 764,532 parameters\n",
      "    Text encoder: 16,024,668 parameters\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "graph_params = sum(p.numel() for p in model.graph_encoder.parameters())\n",
    "text_params = sum(p.numel() for p in model.text_encoder.parameters())\n",
    "\n",
    "print(f'Total number of parameters: {total_params:,}')\n",
    "print(f'    Graph encoder: {graph_params:,} parameters')\n",
    "print(f'    Text encoder: {text_params:,} parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w2v_w2v_model__gps_10_64_764m___128_'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_m_n = graph_config['graph_model_name']\n",
    "g_l = graph_config['graph_layers']\n",
    "g_h_l = graph_config['graph_hidden_channels']\n",
    "pretrained = ''\n",
    "if len(load_graph_pretrained)>0:\n",
    "    pretrained = 'pretrained'\n",
    "\n",
    "model_save_name = f'{model_type}_{model_name}__{g_m_n}_{g_l}_{g_h_l}_{graph_params//1000}m_{pretrained}__128_'\n",
    "model_save_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, losses, device, count_iter, printEvery, time1):\n",
    "    loss = 0\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        if model_type == 'sentence':\n",
    "            sentences = batch.text\n",
    "            batch.pop('text')\n",
    "            graph_batch = batch\n",
    "            \n",
    "            x_graph, x_text = model(graph_batch.to(device), \n",
    "                                    sentences=sentences.to(device))\n",
    "            \n",
    "        else:\n",
    "            input_ids = batch.input_ids\n",
    "            batch.pop('input_ids')\n",
    "            attention_mask = batch.attention_mask\n",
    "            batch.pop('attention_mask')\n",
    "            graph_batch = batch\n",
    "            \n",
    "            x_graph, x_text = model(graph_batch.to(device), \n",
    "                                    input_ids=input_ids.to(device), \n",
    "                                    attention_mask=attention_mask.to(device))\n",
    "            \n",
    "\n",
    "        current_loss = criterion(x_graph, x_text)   \n",
    "        optimizer.zero_grad()\n",
    "        current_loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        loss += current_loss.item()\n",
    "        \n",
    "        count_iter += 1\n",
    "        if count_iter % printEvery == 0:\n",
    "            time2 = time.time()\n",
    "            print(\"Iteration: {0}, Time: {1:.4f} s, training loss: {2:.4f}\".format(count_iter,\n",
    "                                                                        time2 - time1, loss/printEvery))\n",
    "            losses.append(loss)\n",
    "            loss = 0 \n",
    "\n",
    "    return losses, count_iter\n",
    "\n",
    "\n",
    "def eval(model, val_loader, criterion, device):\n",
    "    model.eval()       \n",
    "    val_loss = 0        \n",
    "    for batch in val_loader:\n",
    "        if model_type == 'sentence':\n",
    "            sentences = batch.text\n",
    "            batch.pop('text')\n",
    "            graph_batch = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x_graph, x_text = model(graph_batch.to(device), \n",
    "                                        sentences = sentences.to(device))\n",
    "                current_loss = criterion(x_graph, x_text)   \n",
    "                val_loss += current_loss.item()\n",
    "                \n",
    "        else:\n",
    "            input_ids = batch.input_ids\n",
    "            batch.pop('input_ids')\n",
    "            attention_mask = batch.attention_mask\n",
    "            batch.pop('attention_mask')\n",
    "            graph_batch = batch\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                x_graph, x_text = model(graph_batch.to(device), \n",
    "                                        input_ids=input_ids.to(device), \n",
    "                                        attention_mask=attention_mask.to(device))\n",
    "                current_loss = criterion(x_graph, x_text)   \n",
    "                val_loss += current_loss.item()\n",
    "            \n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save_path = os.path.join('./checkpoints', 'ep'+str(8)+model_save_name+'.pt')\\n\\ncheckpoint = torch.load(save_path)\\nmodel.load_state_dict(checkpoint['model_state_dict'])\\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\\nlr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "\"\"\"save_path = os.path.join('./checkpoints', 'ep'+str(8)+model_save_name+'.pt')\n",
    "\n",
    "checkpoint = torch.load(save_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----EPOCH 1-----\n",
      "Iteration: 50, Time: 103.6072 s, training loss: 0.5959\n",
      "Iteration: 100, Time: 210.7540 s, training loss: 0.5456\n",
      "Iteration: 150, Time: 316.3423 s, training loss: 0.5070\n",
      "Iteration: 200, Time: 422.6605 s, training loss: 0.4765\n",
      "-----EPOCH 1----- done.  Validation loss:  1.706063577518371\n",
      "checkpoint saved to: ./checkpoints/ep0w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 2-----\n",
      "Iteration: 250, Time: 545.0601 s, training loss: 0.3862\n",
      "Iteration: 300, Time: 642.0590 s, training loss: 0.4316\n",
      "Iteration: 350, Time: 744.6805 s, training loss: 0.4146\n",
      "Iteration: 400, Time: 853.1967 s, training loss: 0.3991\n",
      "-----EPOCH 2----- done.  Validation loss:  1.25458218106901\n",
      "checkpoint saved to: ./checkpoints/ep1w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 3-----\n",
      "Iteration: 450, Time: 962.2728 s, training loss: 0.2783\n",
      "Iteration: 500, Time: 1062.4573 s, training loss: 0.3775\n",
      "Iteration: 550, Time: 1180.0532 s, training loss: 0.3685\n",
      "Iteration: 600, Time: 1280.1408 s, training loss: 0.3583\n",
      "-----EPOCH 3----- done.  Validation loss:  1.0686893419942993\n",
      "checkpoint saved to: ./checkpoints/ep2w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 4-----\n",
      "Iteration: 650, Time: 1393.5497 s, training loss: 0.2068\n",
      "Iteration: 700, Time: 1498.9871 s, training loss: 0.3491\n",
      "Iteration: 750, Time: 1590.2794 s, training loss: 0.3398\n",
      "Iteration: 800, Time: 1701.6922 s, training loss: 0.3358\n",
      "-----EPOCH 4----- done.  Validation loss:  0.9597688521739941\n",
      "checkpoint saved to: ./checkpoints/ep3w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 5-----\n",
      "Iteration: 850, Time: 1820.0348 s, training loss: 0.1461\n",
      "Iteration: 900, Time: 1920.6369 s, training loss: 0.3265\n",
      "Iteration: 950, Time: 2031.6986 s, training loss: 0.3228\n",
      "Iteration: 1000, Time: 2144.5297 s, training loss: 0.3163\n",
      "-----EPOCH 5----- done.  Validation loss:  0.8848409531773\n",
      "checkpoint saved to: ./checkpoints/ep4w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 6-----\n",
      "Iteration: 1050, Time: 2258.0709 s, training loss: 0.0958\n",
      "Iteration: 1100, Time: 2376.8859 s, training loss: 0.3092\n",
      "Iteration: 1150, Time: 2491.3294 s, training loss: 0.3039\n",
      "Iteration: 1200, Time: 2601.3126 s, training loss: 0.3020\n",
      "-----EPOCH 6----- done.  Validation loss:  0.8092821967486598\n",
      "checkpoint saved to: ./checkpoints/ep5w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 7-----\n",
      "Iteration: 1250, Time: 2712.9862 s, training loss: 0.0490\n",
      "Iteration: 1300, Time: 2819.2409 s, training loss: 0.2962\n",
      "Iteration: 1350, Time: 2928.9905 s, training loss: 0.2932\n",
      "Iteration: 1400, Time: 3032.8015 s, training loss: 0.2918\n",
      "-----EPOCH 7----- done.  Validation loss:  0.7624571618538548\n",
      "checkpoint saved to: ./checkpoints/ep6w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 8-----\n",
      "Iteration: 1450, Time: 3177.0498 s, training loss: 0.0061\n",
      "Iteration: 1500, Time: 3293.7918 s, training loss: 0.2875\n",
      "Iteration: 1550, Time: 3395.4189 s, training loss: 0.2818\n",
      "Iteration: 1600, Time: 3504.8395 s, training loss: 0.2816\n",
      "Iteration: 1650, Time: 3612.3428 s, training loss: 0.2802\n",
      "-----EPOCH 8----- done.  Validation loss:  0.7299475016225363\n",
      "checkpoint saved to: ./checkpoints/ep7w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 9-----\n",
      "Iteration: 1700, Time: 3739.3001 s, training loss: 0.2435\n",
      "Iteration: 1750, Time: 3840.2639 s, training loss: 0.2786\n",
      "Iteration: 1800, Time: 3948.7668 s, training loss: 0.2713\n",
      "Iteration: 1850, Time: 4067.5138 s, training loss: 0.2726\n",
      "-----EPOCH 9----- done.  Validation loss:  0.7040181717146998\n",
      "checkpoint saved to: ./checkpoints/ep8w2v_w2v_model__gps_10_64_764m___128_.pt\n",
      "-----EPOCH 10-----\n",
      "Iteration: 1900, Time: 4181.1609 s, training loss: 0.2010\n",
      "Iteration: 1950, Time: 4289.7294 s, training loss: 0.2709\n",
      "Iteration: 2000, Time: 4401.6962 s, training loss: 0.2641\n",
      "Iteration: 2050, Time: 4505.0258 s, training loss: 0.2655\n",
      "-----EPOCH 10----- done.  Validation loss:  0.6790202658821419\n",
      "checkpoint saved to: ./checkpoints/ep9w2v_w2v_model__gps_10_64_764m___128_.pt\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "\n",
    "losses = []\n",
    "count_iter = 0\n",
    "time1 = time.time()\n",
    "printEvery = 50\n",
    "best_validation_loss = 1000000\n",
    "\n",
    "\n",
    "for i in range(epoch, nb_epochs):\n",
    "    print('-----EPOCH {}-----'.format(i+1))\n",
    "    losses, count_iter = train_one_epoch(model, train_loader, contrastive_loss, optimizer, losses, device, count_iter, printEvery, time1)\n",
    "\n",
    "    val_loss = eval(model, val_loader, contrastive_loss, device)\n",
    "    \n",
    "    best_validation_loss = min(best_validation_loss, val_loss)\n",
    "\n",
    "    print('-----EPOCH '+str(i+1)+'----- done.  Validation loss: ', str(val_loss/len(val_loader)) )\n",
    "    save_path = os.path.join('./checkpoints', 'ep' + str(i) + model_save_name+'.pt')\n",
    "    torch.save({\n",
    "        'epoch': i,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "        'validation_accuracy': val_loss,\n",
    "        'loss': losses[-1],\n",
    "        }, save_path)\n",
    "    print('checkpoint saved to: {}'.format(save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altegrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
