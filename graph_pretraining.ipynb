{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from Model import GraphCL\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dataloader import GraphDatasetPretrain, AddRWStructEncoding\n",
    "from dataloader import drop_node_augment, edge_pert_augment, attr_mask_augment, subgraph_augment\n",
    "\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('graph_config.json') as f:\n",
    "    graph_config = json.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "walk_length = graph_config['walk_length']\n",
    "nb_epochs = graph_config['pretraining_epochs']\n",
    "batch_size = graph_config['pretraining_batch_size']\n",
    "learning_rate = graph_config['pretraining_lr']\n",
    "weight_decay = graph_config['pretraining_weight_decay']\n",
    "pretraining_scheduler_steps_factor = graph_config['pretraining_scheduler_steps_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load(\"./data/token_embedding_dict.npy\", allow_pickle=True)[()]\n",
    "\n",
    "val_dataset = GraphDatasetPretrain(root='./data/', gt=gt, split='val', \n",
    "                                   graph_augment1=attr_mask_augment, graph_augment2=subgraph_augment, \n",
    "                                   aug_p=0.2, graph_transform=AddRWStructEncoding(walk_length))\n",
    "train_dataset = GraphDatasetPretrain(root='./data/', gt=gt, split='train',\n",
    "                                     graph_augment1=attr_mask_augment, graph_augment2=subgraph_augment,\n",
    "                                     aug_p=0.2, graph_transform=AddRWStructEncoding(walk_length))\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphCL(graph_config, 64, 128)\n",
    "model.to(device)\n",
    "\n",
    "CE = torch.nn.CrossEntropyLoss()\n",
    "def contrastive_loss(v1, v2):\n",
    "  logits = torch.matmul(v1,torch.transpose(v2, 0, 1))\n",
    "  labels = torch.arange(logits.shape[0], device=v1.device)\n",
    "  return (CE(logits, labels) + CE(torch.transpose(logits, 0, 1), labels))/2\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "                                betas=(0.9, 0.999),\n",
    "                                weight_decay=weight_decay, \n",
    "                                eps=1e-08)\n",
    "\n",
    "lr_scheduler = get_scheduler('cosine', optimizer=optimizer, num_warmup_steps=250, \n",
    "                             num_training_steps=len(train_loader)*nb_epochs*pretraining_scheduler_steps_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 526,344\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Number of parameters: {params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, losses, device, count_iter, printEvery, time1):\n",
    "    loss = 0\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        aug_batch1, aug_batch2 = batch\n",
    "        x_1 = model(aug_batch1.to(device))\n",
    "        x_2 = model(aug_batch2.to(device))\n",
    "        \n",
    "        current_loss = criterion(x_1, x_2)   \n",
    "        optimizer.zero_grad()\n",
    "        current_loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        loss += current_loss.item()\n",
    "        \n",
    "        count_iter += 1\n",
    "        if count_iter % printEvery == 0:\n",
    "            time2 = time.time()\n",
    "            print(\"Iteration: {0}, Time: {1:.4f} s, training loss: {2:.4f}\".format(count_iter,\n",
    "                                                                        time2 - time1, loss/printEvery))\n",
    "            losses.append(loss)\n",
    "            loss = 0 \n",
    "\n",
    "    return losses, count_iter\n",
    "\n",
    "\n",
    "def eval(model, val_loader, criterion, device):\n",
    "    model.eval()       \n",
    "    val_loss = 0        \n",
    "    for batch in val_loader:\n",
    "        aug_batch1, aug_batch2 = batch\n",
    "        with torch.no_grad():\n",
    "            x_1 = model(aug_batch1.to(device))\n",
    "            x_2 = model(aug_batch2.to(device))\n",
    "\n",
    "            current_loss = criterion(x_1, x_2)   \n",
    "            val_loss += current_loss.item()\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----EPOCH 1-----\n",
      "Iteration: 50, Time: 24.0918 s, training loss: 4.5393\n",
      "Iteration: 100, Time: 44.8924 s, training loss: 1.9357\n",
      "Iteration: 150, Time: 70.4103 s, training loss: 1.0075\n",
      "Iteration: 200, Time: 96.9311 s, training loss: 0.8094\n",
      "Iteration: 250, Time: 122.9633 s, training loss: 0.7841\n",
      "Iteration: 300, Time: 149.2615 s, training loss: 0.6821\n",
      "Iteration: 350, Time: 173.2303 s, training loss: 0.6124\n",
      "Iteration: 400, Time: 195.5359 s, training loss: 0.4933\n",
      "Iteration: 450, Time: 220.7424 s, training loss: 0.4206\n",
      "Iteration: 500, Time: 251.1807 s, training loss: 0.4535\n",
      "Iteration: 550, Time: 274.6487 s, training loss: 0.4817\n",
      "Iteration: 600, Time: 301.2038 s, training loss: 0.4472\n",
      "Iteration: 650, Time: 324.1943 s, training loss: 0.4142\n",
      "Iteration: 700, Time: 348.5735 s, training loss: 0.3738\n",
      "Iteration: 750, Time: 374.1029 s, training loss: 0.3215\n",
      "Iteration: 800, Time: 400.0661 s, training loss: 0.3409\n",
      "-----EPOCH 1----- done.  Validation loss:  0.31544835880503813\n",
      "checkpoint saved to: ./graph_checkpoints/ep0_gps_10_64_Gated.pt\n",
      "-----EPOCH 2-----\n",
      "Iteration: 850, Time: 473.6154 s, training loss: 0.1757\n",
      "Iteration: 900, Time: 503.1247 s, training loss: 0.3472\n",
      "Iteration: 950, Time: 529.3899 s, training loss: 0.3138\n",
      "Iteration: 1000, Time: 553.0879 s, training loss: 0.3001\n",
      "Iteration: 1050, Time: 578.0226 s, training loss: 0.2897\n",
      "Iteration: 1100, Time: 604.9086 s, training loss: 0.2797\n",
      "Iteration: 1150, Time: 637.0006 s, training loss: 0.2801\n",
      "Iteration: 1200, Time: 665.7771 s, training loss: 0.2433\n",
      "Iteration: 1250, Time: 697.0201 s, training loss: 0.2754\n",
      "Iteration: 1300, Time: 730.6250 s, training loss: 0.2211\n",
      "Iteration: 1350, Time: 762.8254 s, training loss: 0.2830\n",
      "Iteration: 1400, Time: 791.8110 s, training loss: 0.2946\n",
      "Iteration: 1450, Time: 822.3616 s, training loss: 0.2522\n",
      "Iteration: 1500, Time: 853.2814 s, training loss: 0.2364\n",
      "Iteration: 1550, Time: 882.6618 s, training loss: 0.2276\n",
      "Iteration: 1600, Time: 909.7356 s, training loss: 0.2194\n",
      "Iteration: 1650, Time: 939.5920 s, training loss: 0.2227\n",
      "-----EPOCH 2----- done.  Validation loss:  0.2821796261691641\n",
      "checkpoint saved to: ./graph_checkpoints/ep1_gps_10_64_Gated.pt\n",
      "-----EPOCH 3-----\n",
      "Iteration: 1700, Time: 1000.8809 s, training loss: 0.2156\n",
      "Iteration: 1750, Time: 1032.9413 s, training loss: 0.2248\n",
      "Iteration: 1800, Time: 1061.5092 s, training loss: 0.2237\n",
      "Iteration: 1850, Time: 1088.7956 s, training loss: 0.2154\n",
      "Iteration: 1900, Time: 1114.3866 s, training loss: 0.1873\n",
      "Iteration: 1950, Time: 1136.0524 s, training loss: 0.2020\n",
      "Iteration: 2000, Time: 1157.5428 s, training loss: 0.1722\n",
      "Iteration: 2050, Time: 1182.4106 s, training loss: 0.2152\n",
      "Iteration: 2100, Time: 1205.0425 s, training loss: 0.2343\n",
      "Iteration: 2150, Time: 1224.5874 s, training loss: 0.2360\n",
      "Iteration: 2200, Time: 1245.4667 s, training loss: 0.2182\n",
      "Iteration: 2250, Time: 1267.0455 s, training loss: 0.2573\n",
      "Iteration: 2300, Time: 1288.4924 s, training loss: 0.2356\n",
      "Iteration: 2350, Time: 1307.5436 s, training loss: 0.2030\n",
      "Iteration: 2400, Time: 1332.3272 s, training loss: 0.2176\n",
      "Iteration: 2450, Time: 1351.1704 s, training loss: 0.1748\n",
      "-----EPOCH 3----- done.  Validation loss:  0.13664392743073853\n",
      "checkpoint saved to: ./graph_checkpoints/ep2_gps_10_64_Gated.pt\n",
      "-----EPOCH 4-----\n",
      "Iteration: 2500, Time: 1394.2071 s, training loss: 0.0700\n",
      "Iteration: 2550, Time: 1416.0505 s, training loss: 0.1850\n",
      "Iteration: 2600, Time: 1437.0675 s, training loss: 0.1652\n",
      "Iteration: 2650, Time: 1458.1895 s, training loss: 0.2333\n",
      "Iteration: 2700, Time: 1477.8597 s, training loss: 0.2374\n",
      "Iteration: 2750, Time: 1498.8245 s, training loss: 0.2057\n",
      "Iteration: 2800, Time: 1519.2403 s, training loss: 0.1786\n",
      "Iteration: 2850, Time: 1544.6359 s, training loss: 0.1345\n",
      "Iteration: 2900, Time: 1567.6140 s, training loss: 0.1667\n",
      "Iteration: 2950, Time: 1588.1804 s, training loss: 0.1690\n",
      "Iteration: 3000, Time: 1609.8541 s, training loss: 0.1670\n",
      "Iteration: 3050, Time: 1630.0103 s, training loss: 0.1256\n",
      "Iteration: 3100, Time: 1649.8899 s, training loss: 0.1175\n",
      "Iteration: 3150, Time: 1671.9971 s, training loss: 0.1214\n",
      "Iteration: 3200, Time: 1695.5376 s, training loss: 0.1530\n",
      "Iteration: 3250, Time: 1718.7112 s, training loss: 0.2741\n",
      "Iteration: 3300, Time: 1741.1635 s, training loss: 0.1404\n",
      "-----EPOCH 4----- done.  Validation loss:  0.1489440019489708\n",
      "checkpoint saved to: ./graph_checkpoints/ep3_gps_10_64_Gated.pt\n",
      "-----EPOCH 5-----\n",
      "Iteration: 3350, Time: 1786.1696 s, training loss: 0.1353\n",
      "Iteration: 3400, Time: 1808.8393 s, training loss: 0.1344\n",
      "Iteration: 3450, Time: 1830.3371 s, training loss: 0.1502\n",
      "Iteration: 3500, Time: 1851.5685 s, training loss: 0.1130\n",
      "Iteration: 3550, Time: 1873.3015 s, training loss: 0.1384\n",
      "Iteration: 3600, Time: 1897.6421 s, training loss: 0.1276\n",
      "Iteration: 3650, Time: 1918.0219 s, training loss: 0.1138\n",
      "Iteration: 3700, Time: 1940.2975 s, training loss: 0.1410\n",
      "Iteration: 3750, Time: 1961.9700 s, training loss: 0.1281\n",
      "Iteration: 3800, Time: 1982.4256 s, training loss: 0.1430\n",
      "Iteration: 3850, Time: 2002.4954 s, training loss: 0.1415\n",
      "Iteration: 3900, Time: 2024.5497 s, training loss: 0.1606\n",
      "Iteration: 3950, Time: 2046.3581 s, training loss: 0.1131\n",
      "Iteration: 4000, Time: 2069.7652 s, training loss: 0.1348\n",
      "Iteration: 4050, Time: 2091.2461 s, training loss: 0.1325\n",
      "Iteration: 4100, Time: 2113.0142 s, training loss: 0.1347\n",
      "-----EPOCH 5----- done.  Validation loss:  0.10924396470923406\n",
      "checkpoint saved to: ./graph_checkpoints/ep4_gps_10_64_Gated.pt\n",
      "-----EPOCH 6-----\n",
      "Iteration: 4150, Time: 2159.5013 s, training loss: 0.0697\n",
      "Iteration: 4200, Time: 2181.2961 s, training loss: 0.1212\n",
      "Iteration: 4250, Time: 2202.1353 s, training loss: 0.1055\n",
      "Iteration: 4300, Time: 2228.0687 s, training loss: 0.1571\n",
      "Iteration: 4350, Time: 2252.8622 s, training loss: 0.1486\n",
      "Iteration: 4400, Time: 2277.7078 s, training loss: 0.1270\n",
      "Iteration: 4450, Time: 2301.0805 s, training loss: 0.0828\n",
      "Iteration: 4500, Time: 2324.5126 s, training loss: 0.0997\n",
      "Iteration: 4550, Time: 2346.9993 s, training loss: 0.1172\n",
      "Iteration: 4600, Time: 2368.0833 s, training loss: 0.1354\n",
      "Iteration: 4650, Time: 2390.3622 s, training loss: 0.1122\n",
      "Iteration: 4700, Time: 2413.0952 s, training loss: 0.1409\n",
      "Iteration: 4750, Time: 2436.6596 s, training loss: 0.1170\n",
      "Iteration: 4800, Time: 2458.5424 s, training loss: 0.1059\n",
      "Iteration: 4850, Time: 2481.3389 s, training loss: 0.1047\n",
      "Iteration: 4900, Time: 2503.6988 s, training loss: 0.1265\n",
      "Iteration: 4950, Time: 2529.4059 s, training loss: 0.1159\n",
      "-----EPOCH 6----- done.  Validation loss:  0.0829874316478903\n",
      "checkpoint saved to: ./graph_checkpoints/ep5_gps_10_64_Gated.pt\n",
      "-----EPOCH 7-----\n",
      "Iteration: 5000, Time: 2577.6225 s, training loss: 0.1029\n",
      "Iteration: 5050, Time: 2599.0656 s, training loss: 0.1427\n",
      "Iteration: 5100, Time: 2623.8307 s, training loss: 0.1092\n",
      "Iteration: 5150, Time: 2646.9486 s, training loss: 0.0874\n",
      "Iteration: 5200, Time: 2671.1914 s, training loss: 0.1125\n",
      "Iteration: 5250, Time: 2694.5974 s, training loss: 0.0991\n",
      "Iteration: 5300, Time: 2716.3217 s, training loss: 0.1298\n",
      "Iteration: 5350, Time: 2740.2722 s, training loss: 0.1350\n",
      "Iteration: 5400, Time: 2761.6441 s, training loss: 0.1164\n",
      "Iteration: 5450, Time: 2784.3149 s, training loss: 0.1558\n",
      "Iteration: 5500, Time: 2807.2941 s, training loss: 0.1290\n",
      "Iteration: 5550, Time: 2828.3541 s, training loss: 0.1074\n",
      "Iteration: 5600, Time: 2851.5245 s, training loss: 0.1042\n",
      "Iteration: 5650, Time: 2874.9980 s, training loss: 0.1328\n",
      "Iteration: 5700, Time: 2897.2063 s, training loss: 0.1367\n",
      "Iteration: 5750, Time: 2924.6171 s, training loss: 0.1066\n",
      "-----EPOCH 7----- done.  Validation loss:  0.08746935543156444\n",
      "checkpoint saved to: ./graph_checkpoints/ep6_gps_10_64_Gated.pt\n",
      "-----EPOCH 8-----\n",
      "Iteration: 5800, Time: 2975.8384 s, training loss: 0.0388\n",
      "Iteration: 5850, Time: 3000.2739 s, training loss: 0.0791\n",
      "Iteration: 5900, Time: 3022.9572 s, training loss: 0.0814\n",
      "Iteration: 5950, Time: 3050.6150 s, training loss: 0.0845\n",
      "Iteration: 6000, Time: 3073.4708 s, training loss: 0.1082\n",
      "Iteration: 6050, Time: 3096.5853 s, training loss: 0.0964\n",
      "Iteration: 6100, Time: 3118.7778 s, training loss: 0.1075\n",
      "Iteration: 6150, Time: 3140.3775 s, training loss: 0.0765\n",
      "Iteration: 6200, Time: 3165.4118 s, training loss: 0.0700\n",
      "Iteration: 6250, Time: 3186.2881 s, training loss: 0.0939\n",
      "Iteration: 6300, Time: 3210.7179 s, training loss: 0.0753\n",
      "Iteration: 6350, Time: 3233.8691 s, training loss: 0.0808\n",
      "Iteration: 6400, Time: 3258.8562 s, training loss: 0.0827\n",
      "Iteration: 6450, Time: 3283.8539 s, training loss: 0.0448\n",
      "Iteration: 6500, Time: 3305.8716 s, training loss: 0.0840\n",
      "Iteration: 6550, Time: 3328.3661 s, training loss: 0.0977\n",
      "Iteration: 6600, Time: 3349.3419 s, training loss: 0.0827\n",
      "-----EPOCH 8----- done.  Validation loss:  0.06718270306202193\n",
      "checkpoint saved to: ./graph_checkpoints/ep7_gps_10_64_Gated.pt\n",
      "-----EPOCH 9-----\n",
      "Iteration: 6650, Time: 3398.5812 s, training loss: 0.0895\n",
      "Iteration: 6700, Time: 3421.2457 s, training loss: 0.0635\n",
      "Iteration: 6750, Time: 3444.2942 s, training loss: 0.0596\n",
      "Iteration: 6800, Time: 3465.9690 s, training loss: 0.0590\n",
      "Iteration: 6850, Time: 3487.1271 s, training loss: 0.0824\n",
      "Iteration: 6900, Time: 3509.0901 s, training loss: 0.0537\n",
      "Iteration: 6950, Time: 3533.7823 s, training loss: 0.0582\n",
      "Iteration: 7000, Time: 3555.8051 s, training loss: 0.0702\n",
      "Iteration: 7050, Time: 3578.7499 s, training loss: 0.0586\n",
      "Iteration: 7100, Time: 3601.5000 s, training loss: 0.0696\n",
      "Iteration: 7150, Time: 3623.6152 s, training loss: 0.0595\n",
      "Iteration: 7200, Time: 3650.1312 s, training loss: 0.0797\n",
      "Iteration: 7250, Time: 3674.6600 s, training loss: 0.0735\n",
      "Iteration: 7300, Time: 3698.7727 s, training loss: 0.0801\n",
      "Iteration: 7350, Time: 3723.5729 s, training loss: 0.1056\n",
      "Iteration: 7400, Time: 3747.8419 s, training loss: 0.0789\n",
      "-----EPOCH 9----- done.  Validation loss:  0.041480807219539444\n",
      "checkpoint saved to: ./graph_checkpoints/ep8_gps_10_64_Gated.pt\n",
      "-----EPOCH 10-----\n",
      "Iteration: 7450, Time: 3797.9739 s, training loss: 0.0158\n",
      "Iteration: 7500, Time: 3820.6783 s, training loss: 0.0868\n",
      "Iteration: 7550, Time: 3843.4150 s, training loss: 0.0499\n",
      "Iteration: 7600, Time: 3868.3362 s, training loss: 0.0984\n",
      "Iteration: 7650, Time: 3891.3345 s, training loss: 0.0710\n",
      "Iteration: 7700, Time: 3915.5442 s, training loss: 0.0456\n",
      "Iteration: 7750, Time: 3936.9515 s, training loss: 0.0477\n",
      "Iteration: 7800, Time: 3956.4559 s, training loss: 0.0619\n",
      "Iteration: 7850, Time: 3979.2271 s, training loss: 0.0431\n",
      "Iteration: 7900, Time: 4001.1836 s, training loss: 0.0531\n",
      "Iteration: 7950, Time: 4023.1850 s, training loss: 0.0507\n",
      "Iteration: 8000, Time: 4045.2887 s, training loss: 0.0753\n",
      "Iteration: 8050, Time: 4071.6636 s, training loss: 0.0463\n",
      "Iteration: 8100, Time: 4093.4332 s, training loss: 0.0585\n",
      "Iteration: 8150, Time: 4118.3828 s, training loss: 0.0578\n",
      "Iteration: 8200, Time: 4145.6657 s, training loss: 0.0395\n",
      "Iteration: 8250, Time: 4172.2755 s, training loss: 0.0606\n",
      "-----EPOCH 10----- done.  Validation loss:  0.04066664833429128\n",
      "checkpoint saved to: ./graph_checkpoints/ep9_gps_10_64_Gated.pt\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "losses = []\n",
    "count_iter = 0\n",
    "time1 = time.time()\n",
    "printEvery = 50\n",
    "best_validation_loss = 1000000\n",
    "\n",
    "for i in range(nb_epochs):\n",
    "    print('-----EPOCH {}-----'.format(i+1))\n",
    "    losses, count_iter = train_one_epoch(model, train_loader, contrastive_loss, optimizer, losses, device, count_iter, printEvery, time1)\n",
    "\n",
    "    val_loss = eval(model, val_loader, contrastive_loss, device)\n",
    "\n",
    "    best_validation_loss = min(best_validation_loss, val_loss)\n",
    "\n",
    "    print('-----EPOCH '+str(i+1)+'----- done.  Validation loss: ', str(val_loss/len(val_loader)) )\n",
    "    save_name = 'ep' + str(i) + '_' + graph_config['graph_model_name'] + '_' + str(graph_config['graph_layers']) + '_' + \\\n",
    "        str(graph_config['graph_hidden_channels']) + '_' + graph_config['conv_type']\n",
    "    save_path = os.path.join('./graph_checkpoints', save_name +'.pt')\n",
    "    torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.graph_base.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "            'validation_accuracy': val_loss,\n",
    "            'loss': losses[-1],\n",
    "            }, save_path)\n",
    "    print('checkpoint saved to: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved to: ./graph_checkpoints/9_gps_10_64_Gated.pt\n"
     ]
    }
   ],
   "source": [
    "save_name = 'ep' + str(i) + '_' + graph_config['graph_model_name'] + '_' + str(graph_config['graph_layers']) + \\\n",
    "        '_' + str(graph_config['graph_hidden_channels']) + '_' + graph_config['conv_type'] + '_' + graph_config['agg_type']\n",
    "\n",
    "save_path = os.path.join('./graph_checkpoints', save_name +'.pt')\n",
    "torch.save({\n",
    "        'epoch': i,\n",
    "        'model_state_dict': model.graph_base.state_dict(),\n",
    "        'validation_accuracy': val_loss,\n",
    "        'loss': losses[-1],\n",
    "        }, save_path)\n",
    "print('checkpoint saved to: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altegrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
