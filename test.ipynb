{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import GraphTextDataset, GraphDataset, TextDataset, AddRWStructEncoding\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from Model import Model\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch import optim\n",
    "import time\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE = torch.nn.CrossEntropyLoss()\n",
    "def contrastive_loss(v1, v2):\n",
    "  logits = torch.matmul(v1,torch.transpose(v2, 0, 1))\n",
    "  labels = torch.arange(logits.shape[0], device=v1.device)\n",
    "  return CE(logits, labels) + CE(torch.transpose(logits, 0, 1), labels)\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "graph_model_name = 'base'\n",
    "\n",
    "gt = np.load(\"./data/token_embedding_dict.npy\", allow_pickle=True)[()]\n",
    "walk_length = 20\n",
    "val_dataset = GraphTextDataset(root='./data/', gt=gt, split='val', tokenizer=tokenizer, graph_transform=AddRWStructEncoding(walk_length))\n",
    "train_dataset = GraphTextDataset(root='./data/', gt=gt, split='train', tokenizer=tokenizer, graph_transform=AddRWStructEncoding(walk_length))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nb_epochs = 5\n",
    "batch_size_train = 16\n",
    "batch_size_test = 16\n",
    "learning_rate = 2e-5\n",
    "graph_config = {}\n",
    "graph_config['graph_layer'] = 3\n",
    "graph_config['n_head'] = 4\n",
    "graph_config['n_feedforward'] = 128\n",
    "graph_config['input_dropout'] = 0.1\n",
    "graph_config['dropout'] = 0.0\n",
    "graph_config['attention_dropout'] = 0.25\n",
    "graph_config['conv_type'] = 'Gated'\n",
    "graph_config['walk_length'] = 20\n",
    "graph_config['dim_se'] = 28\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_test, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "model = Model(model_name=model_name, graph_model_name=graph_model_name, num_node_features=300, nout=768, nhid=300, graph_hidden_channels=300, graph_config=graph_config) # nout = bert model hidden dim\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate,\n",
    "                                betas=(0.9, 0.999),\n",
    "                                weight_decay=0.01)\n",
    "\n",
    "epoch = 0\n",
    "loss = 0\n",
    "losses = []\n",
    "count_iter = 0\n",
    "time1 = time.time()\n",
    "printEvery = 50\n",
    "best_validation_loss = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 66,956,784\n",
      "    Graph encoder: 593,904 parameters\n",
      "    Text encoder: 66,362,880 parameters\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "graph_params = sum(p.numel() for p in model.graph_encoder.parameters())\n",
    "text_params = sum(p.numel() for p in model.text_encoder.parameters())\n",
    "\n",
    "print(f'Total number of parameters: {total_params:,}')\n",
    "print(f'    Graph encoder: {graph_params:,} parameters')\n",
    "print(f'    Text encoder: {text_params:,} parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert-base-uncased__base_10_64_593m__base_'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_hidden_channels = 64\n",
    "graph_layer = 10\n",
    "\n",
    "model_save_name = f'{model_name}__{graph_model_name}_{graph_layer}_{graph_hidden_channels}_{graph_params//1000}m__base_'\n",
    "model_save_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----EPOCH 1-----\n",
      "Iteration: 50, Time: 57.2708 s, training loss: 6.1487\n",
      "Iteration: 100, Time: 86.3908 s, training loss: 4.9513\n",
      "Iteration: 150, Time: 115.5573 s, training loss: 4.2516\n",
      "Iteration: 200, Time: 145.7405 s, training loss: 3.7652\n",
      "Iteration: 250, Time: 176.1655 s, training loss: 3.4676\n",
      "Iteration: 300, Time: 205.8538 s, training loss: 2.9618\n",
      "Iteration: 350, Time: 235.9578 s, training loss: 2.6791\n",
      "Iteration: 400, Time: 265.8205 s, training loss: 2.5051\n",
      "Iteration: 450, Time: 295.6485 s, training loss: 2.4506\n",
      "Iteration: 500, Time: 325.2785 s, training loss: 2.2394\n",
      "Iteration: 550, Time: 355.1813 s, training loss: 2.3337\n",
      "Iteration: 600, Time: 385.0626 s, training loss: 1.9586\n",
      "Iteration: 650, Time: 415.1148 s, training loss: 1.8303\n",
      "Iteration: 700, Time: 445.0983 s, training loss: 1.8304\n",
      "Iteration: 750, Time: 474.8970 s, training loss: 1.7427\n",
      "Iteration: 800, Time: 504.6938 s, training loss: 1.6192\n",
      "Iteration: 850, Time: 534.5232 s, training loss: 1.4412\n",
      "Iteration: 900, Time: 564.4980 s, training loss: 1.4456\n",
      "Iteration: 950, Time: 594.7271 s, training loss: 1.3925\n",
      "Iteration: 1000, Time: 624.5739 s, training loss: 1.3180\n",
      "Iteration: 1050, Time: 654.2351 s, training loss: 1.3772\n",
      "Iteration: 1100, Time: 684.4150 s, training loss: 1.2015\n",
      "Iteration: 1150, Time: 714.4573 s, training loss: 1.2189\n",
      "Iteration: 1200, Time: 744.3914 s, training loss: 1.1951\n",
      "Iteration: 1250, Time: 774.4932 s, training loss: 1.1954\n",
      "Iteration: 1300, Time: 804.2028 s, training loss: 1.1846\n",
      "Iteration: 1350, Time: 834.3924 s, training loss: 1.1635\n",
      "Iteration: 1400, Time: 864.4551 s, training loss: 1.2811\n",
      "Iteration: 1450, Time: 894.5362 s, training loss: 1.1774\n",
      "Iteration: 1500, Time: 925.2972 s, training loss: 1.1359\n",
      "Iteration: 1550, Time: 954.4245 s, training loss: 1.1942\n",
      "Iteration: 1600, Time: 983.8221 s, training loss: 0.8981\n",
      "Iteration: 1650, Time: 1013.2735 s, training loss: 1.0304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cedric/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----EPOCH 1----- done.  Validation loss:  0.46229666404450903\n",
      "validation loss improved saving checkpoint...\n",
      "checkpoint saved to: ./checkpoints/distilbert-base-uncased__gps_10_64_563m__base_0.pt\n",
      "-----EPOCH 2-----\n",
      "Iteration: 1700, Time: 1100.5266 s, training loss: 0.8687\n",
      "Iteration: 1750, Time: 1131.7850 s, training loss: 0.8996\n",
      "Iteration: 1800, Time: 1161.5148 s, training loss: 0.8910\n",
      "Iteration: 1850, Time: 1191.4225 s, training loss: 0.8263\n",
      "Iteration: 1900, Time: 1221.3418 s, training loss: 0.8947\n",
      "Iteration: 1950, Time: 1252.5566 s, training loss: 0.7691\n",
      "Iteration: 2000, Time: 1282.4204 s, training loss: 0.7597\n",
      "Iteration: 2050, Time: 1312.0023 s, training loss: 0.7370\n",
      "Iteration: 2100, Time: 1348.1531 s, training loss: 0.7069\n",
      "Iteration: 2150, Time: 1382.8558 s, training loss: 0.8399\n",
      "Iteration: 2200, Time: 1414.8659 s, training loss: 0.8374\n",
      "Iteration: 2250, Time: 1447.6664 s, training loss: 0.7106\n",
      "Iteration: 2300, Time: 1480.3001 s, training loss: 0.7179\n",
      "Iteration: 2350, Time: 1510.9931 s, training loss: 0.6430\n",
      "Iteration: 2400, Time: 1541.4040 s, training loss: 0.6869\n",
      "Iteration: 2450, Time: 1571.5316 s, training loss: 0.6549\n",
      "Iteration: 2500, Time: 1604.2010 s, training loss: 0.6043\n",
      "Iteration: 2550, Time: 1638.2738 s, training loss: 0.7355\n",
      "Iteration: 2600, Time: 1670.6881 s, training loss: 0.7266\n",
      "Iteration: 2650, Time: 1702.9999 s, training loss: 0.6681\n",
      "Iteration: 2700, Time: 1735.5123 s, training loss: 0.5350\n",
      "Iteration: 2750, Time: 1767.2703 s, training loss: 0.6588\n",
      "Iteration: 2800, Time: 1799.8822 s, training loss: 0.6131\n",
      "Iteration: 2850, Time: 1833.8415 s, training loss: 0.6362\n",
      "Iteration: 2900, Time: 1864.4056 s, training loss: 0.6415\n",
      "Iteration: 2950, Time: 1896.3456 s, training loss: 0.6288\n",
      "Iteration: 3000, Time: 1929.5431 s, training loss: 0.4945\n",
      "Iteration: 3050, Time: 1962.3066 s, training loss: 0.6188\n",
      "Iteration: 3100, Time: 1993.4023 s, training loss: 0.5826\n",
      "Iteration: 3150, Time: 2026.2194 s, training loss: 0.6061\n",
      "Iteration: 3200, Time: 2057.8946 s, training loss: 0.5632\n",
      "Iteration: 3250, Time: 2089.9374 s, training loss: 0.6428\n",
      "Iteration: 3300, Time: 2122.5874 s, training loss: 0.5229\n",
      "-----EPOCH 2----- done.  Validation loss:  0.2870792736369171\n",
      "validation loss improved saving checkpoint...\n",
      "checkpoint saved to: ./checkpoints/distilbert-base-uncased__gps_10_64_563m__base_1.pt\n",
      "-----EPOCH 3-----\n",
      "Iteration: 3350, Time: 2218.2682 s, training loss: 0.4893\n",
      "Iteration: 3400, Time: 2250.4742 s, training loss: 0.4964\n",
      "Iteration: 3450, Time: 2282.0490 s, training loss: 0.5251\n",
      "Iteration: 3500, Time: 2313.4986 s, training loss: 0.4519\n",
      "Iteration: 3550, Time: 2348.1891 s, training loss: 0.3906\n",
      "Iteration: 3600, Time: 2380.2670 s, training loss: 0.5725\n",
      "Iteration: 3650, Time: 2414.5891 s, training loss: 0.4363\n",
      "Iteration: 3700, Time: 2447.2016 s, training loss: 0.5705\n",
      "Iteration: 3750, Time: 2478.2475 s, training loss: 0.4512\n",
      "Iteration: 3800, Time: 2508.9798 s, training loss: 0.3887\n",
      "Iteration: 3850, Time: 2541.3165 s, training loss: 0.4793\n",
      "Iteration: 3900, Time: 2573.7867 s, training loss: 0.3961\n",
      "Iteration: 3950, Time: 2601.5041 s, training loss: 0.4950\n",
      "Iteration: 4000, Time: 2633.9231 s, training loss: 0.4252\n",
      "Iteration: 4050, Time: 2666.2680 s, training loss: 0.5143\n",
      "Iteration: 4100, Time: 2696.5275 s, training loss: 0.4157\n",
      "Iteration: 4150, Time: 2726.3338 s, training loss: 0.4006\n",
      "Iteration: 4200, Time: 2756.0831 s, training loss: 0.4444\n",
      "Iteration: 4250, Time: 2786.1159 s, training loss: 0.4943\n",
      "Iteration: 4300, Time: 2816.1052 s, training loss: 0.4772\n",
      "Iteration: 4350, Time: 2846.4778 s, training loss: 0.3475\n",
      "Iteration: 4400, Time: 2876.2349 s, training loss: 0.4957\n",
      "Iteration: 4450, Time: 2906.1626 s, training loss: 0.4299\n",
      "Iteration: 4500, Time: 2936.1314 s, training loss: 0.3869\n",
      "Iteration: 4550, Time: 2965.9845 s, training loss: 0.3706\n",
      "Iteration: 4600, Time: 2996.1130 s, training loss: 0.4800\n",
      "Iteration: 4650, Time: 3026.3059 s, training loss: 0.4467\n",
      "Iteration: 4700, Time: 3056.2013 s, training loss: 0.4646\n",
      "Iteration: 4750, Time: 3086.0724 s, training loss: 0.4705\n",
      "Iteration: 4800, Time: 3116.0052 s, training loss: 0.3434\n",
      "Iteration: 4850, Time: 3146.0984 s, training loss: 0.4165\n",
      "Iteration: 4900, Time: 3176.3050 s, training loss: 0.3285\n",
      "Iteration: 4950, Time: 3206.2998 s, training loss: 0.4325\n",
      "-----EPOCH 3----- done.  Validation loss:  0.21890528210419588\n",
      "validation loss improved saving checkpoint...\n",
      "checkpoint saved to: ./checkpoints/distilbert-base-uncased__gps_10_64_563m__base_2.pt\n",
      "-----EPOCH 4-----\n",
      "Iteration: 5000, Time: 3291.9856 s, training loss: 0.3494\n",
      "Iteration: 5050, Time: 3321.8438 s, training loss: 0.3439\n",
      "Iteration: 5100, Time: 3351.8461 s, training loss: 0.2954\n",
      "Iteration: 5150, Time: 3381.8006 s, training loss: 0.2905\n",
      "Iteration: 5200, Time: 3411.4487 s, training loss: 0.3146\n",
      "Iteration: 5250, Time: 3441.0784 s, training loss: 0.3638\n",
      "Iteration: 5300, Time: 3470.8451 s, training loss: 0.4020\n",
      "Iteration: 5350, Time: 3500.7390 s, training loss: 0.3633\n",
      "Iteration: 5400, Time: 3530.6819 s, training loss: 0.3443\n",
      "Iteration: 5450, Time: 3560.1002 s, training loss: 0.3735\n",
      "Iteration: 5500, Time: 3589.8299 s, training loss: 0.3551\n",
      "Iteration: 5550, Time: 3619.7979 s, training loss: 0.2587\n",
      "Iteration: 5600, Time: 3649.2826 s, training loss: 0.3300\n",
      "Iteration: 5650, Time: 3678.9390 s, training loss: 0.3388\n",
      "Iteration: 5700, Time: 3709.1145 s, training loss: 0.3285\n",
      "Iteration: 5750, Time: 3739.1114 s, training loss: 0.3150\n",
      "Iteration: 5800, Time: 3768.6177 s, training loss: 0.3195\n",
      "Iteration: 5850, Time: 3798.1534 s, training loss: 0.2424\n",
      "Iteration: 5900, Time: 3829.3623 s, training loss: 0.2972\n",
      "Iteration: 5950, Time: 3860.1948 s, training loss: 0.3512\n",
      "Iteration: 6000, Time: 3889.9774 s, training loss: 0.2568\n",
      "Iteration: 6050, Time: 3919.5614 s, training loss: 0.2802\n",
      "Iteration: 6100, Time: 3949.0901 s, training loss: 0.3446\n",
      "Iteration: 6150, Time: 3978.9405 s, training loss: 0.2620\n",
      "Iteration: 6200, Time: 4008.9420 s, training loss: 0.2667\n",
      "Iteration: 6250, Time: 4038.7834 s, training loss: 0.3526\n",
      "Iteration: 6300, Time: 4068.3259 s, training loss: 0.2809\n",
      "Iteration: 6350, Time: 4097.9374 s, training loss: 0.3417\n",
      "Iteration: 6400, Time: 4127.7529 s, training loss: 0.2548\n",
      "Iteration: 6450, Time: 4157.7940 s, training loss: 0.3465\n",
      "Iteration: 6500, Time: 4187.6244 s, training loss: 0.3104\n",
      "Iteration: 6550, Time: 4217.3323 s, training loss: 0.2629\n",
      "Iteration: 6600, Time: 4247.0347 s, training loss: 0.2311\n",
      "-----EPOCH 4----- done.  Validation loss:  0.15034203861061468\n",
      "validation loss improved saving checkpoint...\n",
      "checkpoint saved to: ./checkpoints/distilbert-base-uncased__gps_10_64_563m__base_3.pt\n",
      "-----EPOCH 5-----\n",
      "Iteration: 6650, Time: 4332.8386 s, training loss: 0.1920\n",
      "Iteration: 6700, Time: 4362.5518 s, training loss: 0.2314\n",
      "Iteration: 6750, Time: 4392.4851 s, training loss: 0.2408\n",
      "Iteration: 6800, Time: 4422.5253 s, training loss: 0.3256\n",
      "Iteration: 6850, Time: 4452.4656 s, training loss: 0.2752\n",
      "Iteration: 6900, Time: 4482.4197 s, training loss: 0.2618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----EPOCH \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      5\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m      6\u001b[0m     batch\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/altegrad/lib/python3.10/site-packages/torch_geometric/data/dataset.py:263\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03mIn case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03mtuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 263\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/media/cedric/Stockage1/Documents/Cours/MVA/Semestre1/ALTEGRAD/Challenge/Data-Challenge-Molecules/dataloader.py:118\u001b[0m, in \u001b[0;36mGraphTextDataset.get\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 118\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mosp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midx_to_cid\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:169\u001b[0m, in \u001b[0;36m_rebuild_tensor_v2\u001b[0;34m(storage, storage_offset, size, stride, requires_grad, backward_hooks, metadata)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rebuild_tensor_v2\u001b[39m(\n\u001b[1;32m    167\u001b[0m     storage, storage_offset, size, stride, requires_grad, backward_hooks, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    168\u001b[0m ):\n\u001b[0;32m--> 169\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43m_rebuild_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     tensor\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m requires_grad\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:147\u001b[0m, in \u001b[0;36m_rebuild_tensor\u001b[0;34m(storage, storage_offset, size, stride)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rebuild_tensor\u001b[39m(storage, storage_offset, size, stride):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# first construct a tensor with the correct dtype/device\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_untyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mset_(storage\u001b[38;5;241m.\u001b[39m_untyped_storage, storage_offset, size, stride)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(nb_epochs):\n",
    "    print('-----EPOCH {}-----'.format(i+1))\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch.input_ids\n",
    "        batch.pop('input_ids')\n",
    "        attention_mask = batch.attention_mask\n",
    "        batch.pop('attention_mask')\n",
    "        graph_batch = batch\n",
    "        \n",
    "        x_graph, x_text = model(graph_batch.to(device), \n",
    "                                input_ids.to(device), \n",
    "                                attention_mask.to(device))\n",
    "        current_loss = contrastive_loss(x_graph, x_text)   \n",
    "        optimizer.zero_grad()\n",
    "        current_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += current_loss.item()\n",
    "        \n",
    "        count_iter += 1\n",
    "        if count_iter % printEvery == 0:\n",
    "            time2 = time.time()\n",
    "            print(\"Iteration: {0}, Time: {1:.4f} s, training loss: {2:.4f}\".format(count_iter,\n",
    "                                                                        time2 - time1, loss/printEvery))\n",
    "            losses.append(loss)\n",
    "            loss = 0 \n",
    "\n",
    "    model.eval()       \n",
    "    val_loss = 0        \n",
    "    for batch in val_loader:\n",
    "        input_ids = batch.input_ids\n",
    "        batch.pop('input_ids')\n",
    "        attention_mask = batch.attention_mask\n",
    "        batch.pop('attention_mask')\n",
    "        graph_batch = batch\n",
    "        with torch.no_grad():\n",
    "            x_graph, x_text = model(graph_batch.to(device), \n",
    "                                    input_ids.to(device), \n",
    "                                    attention_mask.to(device))\n",
    "            current_loss = contrastive_loss(x_graph, x_text)   \n",
    "            val_loss += current_loss.item()\n",
    "    best_validation_loss = min(best_validation_loss, val_loss)\n",
    "\n",
    "    print('-----EPOCH '+str(i+1)+'----- done.  Validation loss: ', str(val_loss/len(val_loader)) )\n",
    "    if best_validation_loss==val_loss:\n",
    "        print('validation loss improved saving checkpoint...')\n",
    "        save_path = os.path.join('./checkpoints', model_save_name+str(i)+'.pt')\n",
    "        torch.save({\n",
    "        'epoch': i,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'validation_accuracy': val_loss,\n",
    "        'loss': loss,\n",
    "        }, save_path)\n",
    "        print('checkpoint saved to: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading best model...\n"
     ]
    }
   ],
   "source": [
    "#save_path = os.path.join('./checkpoints', 'model'+str(4)+'.pt')\n",
    "\n",
    "print('loading best model...')\n",
    "checkpoint = torch.load(save_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "graph_model = model.get_graph_encoder()\n",
    "text_model = model.get_text_encoder()\n",
    "\n",
    "test_cids_dataset = GraphDataset(root='./data/', gt=gt, split='test_cids')\n",
    "test_text_dataset = TextDataset(file_path='./data/test_text.txt', tokenizer=tokenizer)\n",
    "\n",
    "idx_to_cid = test_cids_dataset.get_idx_to_cid()\n",
    "\n",
    "test_loader = DataLoader(test_cids_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "graph_embeddings = []\n",
    "for batch in test_loader:\n",
    "    for output in graph_model(batch.to(device)):\n",
    "        graph_embeddings.append(output.tolist())\n",
    "\n",
    "test_text_loader = TorchDataLoader(test_text_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "text_embeddings = []\n",
    "for batch in test_text_loader:\n",
    "    for output in text_model(batch['input_ids'].to(device), \n",
    "                             attention_mask=batch['attention_mask'].to(device)):\n",
    "        text_embeddings.append(output.tolist())\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(text_embeddings, graph_embeddings)\n",
    "\n",
    "solution = pd.DataFrame(similarity)\n",
    "solution['ID'] = solution.index\n",
    "solution = solution[['ID'] + [col for col in solution.columns if col!='ID']]\n",
    "solution.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_name = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Model:\n\tMissing key(s) in state_dict: \"graph_encoder.conv_layers.0.bias\", \"graph_encoder.conv_layers.0.lin.weight\", \"graph_encoder.conv_layers.1.bias\", \"graph_encoder.conv_layers.1.lin.weight\", \"graph_encoder.conv_layers.2.bias\", \"graph_encoder.conv_layers.2.lin.weight\". \n\tUnexpected key(s) in state_dict: \"graph_encoder.conv1.bias\", \"graph_encoder.conv1.lin.weight\", \"graph_encoder.conv2.bias\", \"graph_encoder.conv2.lin.weight\", \"graph_encoder.conv3.bias\", \"graph_encoder.conv3.lin.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m, model_save_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(save_path)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()       \n\u001b[1;32m      6\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m        \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model:\n\tMissing key(s) in state_dict: \"graph_encoder.conv_layers.0.bias\", \"graph_encoder.conv_layers.0.lin.weight\", \"graph_encoder.conv_layers.1.bias\", \"graph_encoder.conv_layers.1.lin.weight\", \"graph_encoder.conv_layers.2.bias\", \"graph_encoder.conv_layers.2.lin.weight\". \n\tUnexpected key(s) in state_dict: \"graph_encoder.conv1.bias\", \"graph_encoder.conv1.lin.weight\", \"graph_encoder.conv2.bias\", \"graph_encoder.conv2.lin.weight\", \"graph_encoder.conv3.bias\", \"graph_encoder.conv3.lin.weight\". "
     ]
    }
   ],
   "source": [
    "for i in range(nb_epochs):\n",
    "    save_path = os.path.join('./checkpoints', model_save_name+str(i)+'.pt')\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()       \n",
    "    val_loss = 0        \n",
    "    for batch in val_loader:\n",
    "        input_ids = batch.input_ids\n",
    "        batch.pop('input_ids')\n",
    "        attention_mask = batch.attention_mask\n",
    "        batch.pop('attention_mask')\n",
    "        graph_batch = batch\n",
    "        with torch.no_grad():\n",
    "            x_graph, x_text = model(graph_batch.to(device), \n",
    "                                    input_ids.to(device), \n",
    "                                    attention_mask.to(device))\n",
    "            current_loss = contrastive_loss(x_graph, x_text)   \n",
    "            val_loss += current_loss.item()\n",
    "\n",
    "    print('-----EPOCH '+str(i+1)+'----- done.  Validation loss: ', str(val_loss/len(val_loader)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "input_ids = batch.input_ids\n",
    "batch.pop('input_ids')\n",
    "attention_mask = batch.attention_mask\n",
    "batch.pop('attention_mask')\n",
    "graph_batch = batch\n",
    "with torch.no_grad():\n",
    "    x_graph, x_text = model(graph_batch.to(device), \n",
    "                                    input_ids.to(device), \n",
    "                                    attention_mask.to(device))\n",
    "    print(x_graph.shape)\n",
    "    print(x_text.shape)\n",
    "    current_loss = contrastive_loss(x_graph, x_text)   \n",
    "    val_loss += current_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altegrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
